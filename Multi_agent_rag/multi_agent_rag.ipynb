{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi_Agent_Rag\n"
     ]
    }
   ],
   "source": [
    "print('Multi_Agent_Rag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"openai_api_key\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"True\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"langsmith_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(\"attention_is_all_you_need.pdf\")\n",
    "Attention=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=800,chunk_overlap=200)\n",
    "Attention_split=text_splitter.split_documents(Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention_db=Chroma.from_documents(Attention_split,OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000290E67C7620>, search_kwargs={})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_retriever=Attention_db.as_retriever()\n",
    "pdf_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "pdf_retriever_tool=create_retriever_tool(pdf_retriever,\"Pdf_search\",\"A tool to search for and extract information from PDF documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Pdf_search', description='A tool to search for and extract information from PDF documents', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000290E0FF2D40>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000290E67C7620>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000290E14189A0>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000290E67C7620>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=[pdf_retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4-turbo\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "Prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "Prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000290E0A20540>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000290E0A20540>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000290E15902C0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000290E1591850>, root_client=<openai.OpenAI object at 0x00000290E5E2B530>, root_async_client=<openai.AsyncOpenAI object at 0x00000290E5CBD340>, model_name='gpt-4-turbo', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Pdf_search', 'description': 'A tool to search for and extract information from PDF documents', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='Pdf_search', description='A tool to search for and extract information from PDF documents', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000290E0FF2D40>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000290E67C7620>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000290E14189A0>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000290E67C7620>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Pdf_search` with `{'query': 'authors of the paper Attention is all you need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mProvided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.comNoam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.comNiki Parmar∗\n",
      "Google Research\n",
      "nikip@google.comJakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.comAidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.eduŁukasz Kaiser∗\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin∗ ‡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "\n",
      "[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\n",
      "Information Processing Systems, (NIPS) , 2016.\n",
      "[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\n",
      "on Learning Representations (ICLR) , 2016.\n",
      "[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\n",
      "ray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2 ,\n",
      "2017.\n",
      "[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\n",
      "InInternational Conference on Learning Representations , 2017.\n",
      "[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR , 2015.\n",
      "\n",
      "Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\n",
      "and 6. Note that the attentions are very sharp for this word.\n",
      "14\n",
      "\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\n",
      "Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\u001b[0m\u001b[32;1m\u001b[1;3mThe authors of the paper \"Attention Is All You Need\" are:\n",
      "\n",
      "- Ashish Vaswani\n",
      "- Noam Shazeer\n",
      "- Niki Parmar\n",
      "- Jakob Uszkoreit\n",
      "- Llion Jones\n",
      "- Aidan N. Gomez\n",
      "- Łukasz Kaiser\n",
      "- Illia Polosukhin\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who are authors of paper Attention is all you need',\n",
       " 'output': 'The authors of the paper \"Attention Is All You Need\" are:\\n\\n- Ashish Vaswani\\n- Noam Shazeer\\n- Niki Parmar\\n- Jakob Uszkoreit\\n- Llion Jones\\n- Aidan N. Gomez\\n- Łukasz Kaiser\\n- Illia Polosukhin'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Who are authors of paper Attention is all you need\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIn the context of data management and programming, the terms \"query,\" \"key,\" and \"value\" have specific meanings:\n",
      "\n",
      "1. **Query:**\n",
      "   - A query is a request for information or data from a database, system, or specific data structure. In databases, a query is often written in a query language, such as SQL (Structured Query Language), which allows the user to specify what data is needed and how it should be processed or filtered. Queries can also be used in other contexts, such as web search engines or APIs, where they represent a request for data or some operation.\n",
      "\n",
      "2. **Key:**\n",
      "   - A key is an identifier used in data structures, such as arrays, maps, or databases, to uniquely identify an element or a record. In databases, a key is used to find and retrieve data quickly. For example, in a relational database, a primary key is a specific choice of a minimal set of attributes (columns) that uniquely specify a tuple (row) in a table. In programming, keys are used in associative arrays (also known as maps or dictionaries) to associate each unique key with a value.\n",
      "\n",
      "3. **Value:**\n",
      "   - A value is the data associated with a key in key-value pairs within data structures like dictionaries, maps, or databases. In a dictionary, for example, each key is paired with a value; the key is used to retrieve the associated value. Values can be numbers, strings, objects, or even complex data structures.\n",
      "\n",
      "Together, keys and values are fundamental components of many data storage and retrieval systems, enabling efficient data management and querying capabilities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is query,key and value ?',\n",
       " 'output': 'In the context of data management and programming, the terms \"query,\" \"key,\" and \"value\" have specific meanings:\\n\\n1. **Query:**\\n   - A query is a request for information or data from a database, system, or specific data structure. In databases, a query is often written in a query language, such as SQL (Structured Query Language), which allows the user to specify what data is needed and how it should be processed or filtered. Queries can also be used in other contexts, such as web search engines or APIs, where they represent a request for data or some operation.\\n\\n2. **Key:**\\n   - A key is an identifier used in data structures, such as arrays, maps, or databases, to uniquely identify an element or a record. In databases, a key is used to find and retrieve data quickly. For example, in a relational database, a primary key is a specific choice of a minimal set of attributes (columns) that uniquely specify a tuple (row) in a table. In programming, keys are used in associative arrays (also known as maps or dictionaries) to associate each unique key with a value.\\n\\n3. **Value:**\\n   - A value is the data associated with a key in key-value pairs within data structures like dictionaries, maps, or databases. In a dictionary, for example, each key is paired with a value; the key is used to retrieve the associated value. Values can be numbers, strings, objects, or even complex data structures.\\n\\nTogether, keys and values are fundamental components of many data storage and retrieval systems, enabling efficient data management and querying capabilities.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is query,key and value ?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "llama_key=os.getenv(\"llama_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=LlamaParse(api_key=llama_key,result_type=\"markdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id f360318e-0e4f-4c76-b81f-4f715e89d101\n"
     ]
    }
   ],
   "source": [
    "documents=parser.load_data(\"pokemon_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt=OpenAI(model=\"gpt-4-turbo\")\n",
    "Settings.llm=gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "index=VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The differences between Kyurem Black Kyurem and Kyurem White Kyurem are as follows:\\n\\n1. Attack and Special Attack stats:\\n   - Kyurem Black Kyurem has a higher Attack stat of 170 compared to Kyurem White Kyurem's Attack stat of 120.\\n   - Kyurem White Kyurem has a higher Special Attack stat of 170 compared to Kyurem Black Kyurem's Special Attack stat of 120.\\n\\n2. Defense and Special Defense stats:\\n   - Both forms have the same Defense stat of 100.\\n   - Kyurem White Kyurem has a higher Special Defense stat of 100 compared to Kyurem Black Kyurem's Special Defense stat of 90.\\n\\nAll other stats including HP, Speed, and Generation are the same for both forms. Both are also classified as Dragon/Ice types and are marked as TRUE for a specific unidentified attribute.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=query_engine.query(\"Difference between KyuremBlack Kyurem and KyuremWhite Kyurem ?\")\n",
    "str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "def excel_search_tool(input_text:str):\n",
    "    response=query_engine.query(input_text)\n",
    "    return str(response)\n",
    "\n",
    "excel_retriever_tool=Tool(\n",
    "    name=\"Excel_search\",\n",
    "    func=excel_search_tool,\n",
    "    description=\"A tool to search for and extract information from Excel documents\"\n",
    ")\n",
    "\n",
    "tools=[pdf_retriever_tool,excel_retriever_tool]\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThere are many Grass-type Pokémon across the various generations of Pokémon games. Here is a list of some notable Grass-type Pokémon from various generations:\n",
      "\n",
      "1. **Bulbasaur**\n",
      "2. **Ivysaur**\n",
      "3. **Venusaur**\n",
      "4. **Oddish**\n",
      "5. **Gloom**\n",
      "6. **Vileplume**\n",
      "7. **Paras**\n",
      "8. **Parasect**\n",
      "9. **Bellsprout**\n",
      "10. **Weepinbell**\n",
      "11. **Victreebel**\n",
      "12. **Exeggcute**\n",
      "13. **Exeggutor**\n",
      "14. **Tangela**\n",
      "15. **Chikorita**\n",
      "16. **Bayleef**\n",
      "17. **Meganium**\n",
      "18. **Bellossom**\n",
      "19. **Hoppip**\n",
      "20. **Skiploom**\n",
      "21. **Jumpluff**\n",
      "22. **Sunkern**\n",
      "23. **Sunflora**\n",
      "24. **Treecko**\n",
      "25. **Grovyle**\n",
      "26. **Sceptile**\n",
      "27. **Shroomish**\n",
      "28. **Breloom**\n",
      "29. **Roselia**\n",
      "30. **Cacnea**\n",
      "31. **Cacturne**\n",
      "32. **Lileep**\n",
      "33. **Cradily**\n",
      "34. **Tropius**\n",
      "35. **Turtwig**\n",
      "36. **Grotle**\n",
      "37. **Torterra**\n",
      "38. **Budew**\n",
      "39. **Roserade**\n",
      "40. **Carnivine**\n",
      "41. **Snover**\n",
      "42. **Abomasnow**\n",
      "43. **Tangrowth**\n",
      "44. **Leafeon**\n",
      "45. **Shaymin**\n",
      "46. **Snivy**\n",
      "47. **Servine**\n",
      "48. **Serperior**\n",
      "49. **Pansage**\n",
      "50. **Simisage**\n",
      "51. **Sewaddle**\n",
      "52. **Swadloon**\n",
      "53. **Leavanny**\n",
      "54. **Cottonee**\n",
      "55. **Whimsicott**\n",
      "56. **Petilil**\n",
      "57. **Lilligant**\n",
      "58. **Maractus**\n",
      "59. **Deerling**\n",
      "60. **Sawsbuck**\n",
      "61. **Foongus**\n",
      "62. **Amoonguss**\n",
      "63. **Ferroseed**\n",
      "64. **Ferrothorn**\n",
      "65. **Chespin**\n",
      "66. **Quilladin**\n",
      "67. **Chesnaught**\n",
      "68. **Skiddo**\n",
      "69. **Gogoat**\n",
      "70. **Phantump**\n",
      "71. **Trevenant**\n",
      "72. **Pumpkaboo**\n",
      "73. **Gourgeist**\n",
      "74. **Rowlet**\n",
      "75. **Dartrix**\n",
      "76. **Decidueye**\n",
      "77. **Fomantis**\n",
      "78. **Lurantis**\n",
      "79. **Morelull**\n",
      "80. **Shiinotic**\n",
      "81. **Bounsweet**\n",
      "82. **Steenee**\n",
      "83. **Tsareena**\n",
      "84. **Dhelmise**\n",
      "85. **Grookey**\n",
      "86. **Thwackey**\n",
      "87. **Rillaboom**\n",
      "88. **Eldegoss**\n",
      "89. **Gossifleur**\n",
      "90. **Flapple**\n",
      "91. **Appletun**\n",
      "\n",
      "This list includes only some of the Grass-type Pokémon, and there are more, especially with new generations and regional variants.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Name all Grass type Pokemons ?', 'output': 'There are many Grass-type Pokémon across the various generations of Pokémon games. Here is a list of some notable Grass-type Pokémon from various generations:\\n\\n1. **Bulbasaur**\\n2. **Ivysaur**\\n3. **Venusaur**\\n4. **Oddish**\\n5. **Gloom**\\n6. **Vileplume**\\n7. **Paras**\\n8. **Parasect**\\n9. **Bellsprout**\\n10. **Weepinbell**\\n11. **Victreebel**\\n12. **Exeggcute**\\n13. **Exeggutor**\\n14. **Tangela**\\n15. **Chikorita**\\n16. **Bayleef**\\n17. **Meganium**\\n18. **Bellossom**\\n19. **Hoppip**\\n20. **Skiploom**\\n21. **Jumpluff**\\n22. **Sunkern**\\n23. **Sunflora**\\n24. **Treecko**\\n25. **Grovyle**\\n26. **Sceptile**\\n27. **Shroomish**\\n28. **Breloom**\\n29. **Roselia**\\n30. **Cacnea**\\n31. **Cacturne**\\n32. **Lileep**\\n33. **Cradily**\\n34. **Tropius**\\n35. **Turtwig**\\n36. **Grotle**\\n37. **Torterra**\\n38. **Budew**\\n39. **Roserade**\\n40. **Carnivine**\\n41. **Snover**\\n42. **Abomasnow**\\n43. **Tangrowth**\\n44. **Leafeon**\\n45. **Shaymin**\\n46. **Snivy**\\n47. **Servine**\\n48. **Serperior**\\n49. **Pansage**\\n50. **Simisage**\\n51. **Sewaddle**\\n52. **Swadloon**\\n53. **Leavanny**\\n54. **Cottonee**\\n55. **Whimsicott**\\n56. **Petilil**\\n57. **Lilligant**\\n58. **Maractus**\\n59. **Deerling**\\n60. **Sawsbuck**\\n61. **Foongus**\\n62. **Amoonguss**\\n63. **Ferroseed**\\n64. **Ferrothorn**\\n65. **Chespin**\\n66. **Quilladin**\\n67. **Chesnaught**\\n68. **Skiddo**\\n69. **Gogoat**\\n70. **Phantump**\\n71. **Trevenant**\\n72. **Pumpkaboo**\\n73. **Gourgeist**\\n74. **Rowlet**\\n75. **Dartrix**\\n76. **Decidueye**\\n77. **Fomantis**\\n78. **Lurantis**\\n79. **Morelull**\\n80. **Shiinotic**\\n81. **Bounsweet**\\n82. **Steenee**\\n83. **Tsareena**\\n84. **Dhelmise**\\n85. **Grookey**\\n86. **Thwackey**\\n87. **Rillaboom**\\n88. **Eldegoss**\\n89. **Gossifleur**\\n90. **Flapple**\\n91. **Appletun**\\n\\nThis list includes only some of the Grass-type Pokémon, and there are more, especially with new generations and regional variants.'}\n"
     ]
    }
   ],
   "source": [
    "response=agent_executor.invoke({\"input\":\"Name all Grass type Pokemons ?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Pdf_search` with `{'query': 'query, key, value in Attention is All You Need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mvalues.\n",
      "In practice, we compute the attention function on a set of queries simultaneously, packed together\n",
      "into a matrix Q. The keys and values are also packed together into matrices KandV. We compute\n",
      "the matrix of outputs as:\n",
      "Attention( Q, K, V ) = softmax(QKT\n",
      "√dk)V (1)\n",
      "The two most commonly used attention functions are additive attention [ 2], and dot-product (multi-\n",
      "plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\n",
      "of1√dk. Additive attention computes the compatibility function using a feed-forward network with\n",
      "a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\n",
      "much faster and more space-efficient in practice, since it can be implemented using highly optimized\n",
      "\n",
      "Scaled Dot-Product Attention\n",
      " Multi-Head Attention\n",
      "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\n",
      "attention layers running in parallel.\n",
      "of the values, where the weight assigned to each value is computed by a compatibility function of the\n",
      "query with the corresponding key.\n",
      "3.2.1 Scaled Dot-Product Attention\n",
      "We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\n",
      "queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\n",
      "query with all keys, divide each by√dk, and apply a softmax function to obtain the weights on the\n",
      "values.\n",
      "In practice, we compute the attention function on a set of queries simultaneously, packed together\n",
      "\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\n",
      "sentence. We give two such examples above, from two different heads from the encoder self-attention\n",
      "\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\n",
      "Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Pdf_search` with `{'query': 'attention mechanism in Attention is All You Need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
      "2 Background\n",
      "\n",
      "Attention Visualizations\n",
      "Input-Input Layer5\n",
      "It\n",
      "is\n",
      "in\n",
      "this\n",
      "spirit\n",
      "that\n",
      "a\n",
      "majority\n",
      "of\n",
      "American\n",
      "governments\n",
      "have\n",
      "passed\n",
      "new\n",
      "laws\n",
      "since\n",
      "2009\n",
      "making\n",
      "the\n",
      "registration\n",
      "or\n",
      "voting\n",
      "process\n",
      "more\n",
      "difficult\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "It\n",
      "is\n",
      "in\n",
      "this\n",
      "spirit\n",
      "that\n",
      "a\n",
      "majority\n",
      "of\n",
      "American\n",
      "governments\n",
      "have\n",
      "passed\n",
      "new\n",
      "laws\n",
      "since\n",
      "2009\n",
      "making\n",
      "the\n",
      "registration\n",
      "or\n",
      "voting\n",
      "process\n",
      "more\n",
      "difficult\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "Figure 3: An example of the attention mechanism following long-distance dependencies in the\n",
      "encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\n",
      "the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\n",
      "\n",
      "Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\n",
      "and 6. Note that the attentions are very sharp for this word.\n",
      "14\n",
      "\n",
      "the approach we take in our model.\n",
      "As side benefit, self-attention could yield more interpretable models. We inspect attention distributions\n",
      "from our models and present and discuss examples in the appendix. Not only do individual attention\n",
      "heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\n",
      "and semantic structure of the sentences.\n",
      "5 Training\n",
      "This section describes the training regime for our models.\n",
      "5.1 Training Data and Batching\n",
      "We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\n",
      "sentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\n",
      "target vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\u001b[0m\u001b[32;1m\u001b[1;3mIn the paper \"Attention is All You Need,\" the concepts of query, key, and value are central to the attention mechanism described, specifically the \"Scaled Dot-Product Attention.\"\n",
      "\n",
      "Here's a breakdown of these terms:\n",
      "\n",
      "1. **Query (Q)**: A query is a representation of an input element that is used to score against all keys. It is part of the input to the attention mechanism and is used to compute the attention scores.\n",
      "\n",
      "2. **Key (K)**: A key is associated with each value in the dataset. The attention mechanism computes the compatibility of a query with each key to determine the attention weights.\n",
      "\n",
      "3. **Value (V)**: A value is the actual content element that the attention mechanism aims to focus on. The attention scores (derived from the query and key compatibility) are used to create a weighted sum of these values, which forms the output of the attention mechanism.\n",
      "\n",
      "The attention function is computed as follows:\n",
      "\\[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\]\n",
      "where \\(d_k\\) is the dimensionality of the keys.\n",
      "\n",
      "This mechanism allows the model to dynamically focus on different parts of the input sequence, which is crucial for tasks like translation where different parts of the input sequence may be more relevant at different stages of processing. The use of multiple such attention mechanisms in parallel, termed \"Multi-Head Attention,\" allows the model to attend to information from different representation subspaces at different positions, enhancing its ability to model complex dependencies.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is query,key and value in paper attention is all you need?', 'output': 'In the paper \"Attention is All You Need,\" the concepts of query, key, and value are central to the attention mechanism described, specifically the \"Scaled Dot-Product Attention.\"\\n\\nHere\\'s a breakdown of these terms:\\n\\n1. **Query (Q)**: A query is a representation of an input element that is used to score against all keys. It is part of the input to the attention mechanism and is used to compute the attention scores.\\n\\n2. **Key (K)**: A key is associated with each value in the dataset. The attention mechanism computes the compatibility of a query with each key to determine the attention weights.\\n\\n3. **Value (V)**: A value is the actual content element that the attention mechanism aims to focus on. The attention scores (derived from the query and key compatibility) are used to create a weighted sum of these values, which forms the output of the attention mechanism.\\n\\nThe attention function is computed as follows:\\n\\\\[ \\\\text{Attention}(Q, K, V) = \\\\text{softmax}\\\\left(\\\\frac{QK^T}{\\\\sqrt{d_k}}\\\\right)V \\\\]\\nwhere \\\\(d_k\\\\) is the dimensionality of the keys.\\n\\nThis mechanism allows the model to dynamically focus on different parts of the input sequence, which is crucial for tasks like translation where different parts of the input sequence may be more relevant at different stages of processing. The use of multiple such attention mechanisms in parallel, termed \"Multi-Head Attention,\" allows the model to attend to information from different representation subspaces at different positions, enhancing its ability to model complex dependencies.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\":\"What is query,key and value in paper attention is all you need ?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
